{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KAFKA CONSUMER PARA SUPLEMENTOS DEPORTIVOS \"**GAINSIGHT**\"\n",
        "### Este notebook consume mensajes del t√≥pico 'supplement_products' y los almacena en MongoDB para su posterior an√°lisis en el dashboard de Streamlit.\n",
        "### Arquitectura: Kafka ‚Üí Consumer Python ‚Üí MongoDB ‚Üí Streamlit Dashboard\n",
        "### Pipeline: Producer ‚Üí Consumer ‚Üí Database ‚Üí Analytics"
      ],
      "metadata": {
        "id": "sqIU-kRNyG_q"
      },
      "id": "sqIU-kRNyG_q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importaci√≥n de Librer√≠as\n",
        "\n",
        "### Importamos las librer√≠as necesarias para:\n",
        "- **PyMongo**: Conexi√≥n y operaciones con MongoDB\n",
        "- **Kafka**: Consumer de mensajes de Kafka\n",
        "- **JSON**: Deserializaci√≥n de mensajes\n",
        "- **Time/Datetime**: Control de tiempo y timestamps\n",
        "- **Pprint**: Visualizaci√≥n mejorada de datos"
      ],
      "metadata": {
        "id": "MmG-7nY7ylNb"
      },
      "id": "MmG-7nY7ylNb"
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from kafka import KafkaConsumer\n",
        "from json import loads\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "import logging\n",
        "from collections import Counter\n",
        "\n",
        "# Configurar logging para mejor debugging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "Un98--_Fyk2D"
      },
      "id": "Un98--_Fyk2D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraci√≥n de MongoDB\n",
        "Establecemos la conexi√≥n con MongoDB donde almacenaremos los productos.\n",
        "\n",
        "### Estructura de la base de datos:\n",
        "- **Database**: `fitness_supplements` - Espec√≠fica para suplementos deportivos\n",
        "- **Collection**: `products` - Almacena todos los productos procesados\n",
        "\n",
        "### Validaciones incluidas:\n",
        "- Verificaci√≥n de conexi√≥n a MongoDB\n",
        "- Validaci√≥n de base de datos y colecci√≥n\n",
        "- Manejo de errores de conectividad\n"
      ],
      "metadata": {
        "id": "sR9lXY5_zTuS"
      },
      "id": "sR9lXY5_zTuS"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîó Configurando conexi√≥n con MongoDB...\")\n",
        "\n",
        "try:\n",
        "    # Establecer conexi√≥n con MongoDB\n",
        "    client = MongoClient(\n",
        "        \"mongodb://localhost:27017/\",\n",
        "        serverSelectionTimeoutMS=5000,  # Timeout de 5 segundos\n",
        "        connectTimeoutMS=5000\n",
        "    )\n",
        "\n",
        "    # Verificar conexi√≥n\n",
        "    client.admin.command('ping')\n",
        "    print(\"‚úÖ Conexi√≥n con MongoDB establecida\")\n",
        "\n",
        "    # Configurar base de datos y colecci√≥n\n",
        "    database = client[\"fitness_supplements\"]\n",
        "    collection = database[\"products\"]\n",
        "\n",
        "    print(f\"Base de datos: {database.name}\")\n",
        "    print(f\"Colecci√≥n: {collection.name}\")\n",
        "\n",
        "    # Mostrar estad√≠sticas actuales\n",
        "    current_count = collection.count_documents({})\n",
        "    print(f\"Documentos actuales en la colecci√≥n: {current_count:,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error conectando a MongoDB: {e}\")\n",
        "    print(\"Soluci√≥n: Aseg√∫rate que MongoDB est√° ejecut√°ndose en localhost:27017\")\n",
        "    print(\"   Comando: mongod --dbpath /path/to/data\")\n",
        "    raise e"
      ],
      "metadata": {
        "id": "86xQZFsczasl"
      },
      "id": "86xQZFsczasl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuraci√≥n del Consumer Kafka\n",
        "Configuramos el consumer para recibir mensajes del t√≥pico de suplementos.\n",
        "###Par√°metros importantes:\n",
        "- **auto_offset_reset='earliest'**: Lee desde el inicio del t√≥pico\n",
        "- **consumer_timeout_ms**: Timeout para evitar bloqueos indefinidos\n",
        "- **group_id**: Identificador del grupo de consumers para manejo de offsets\n",
        "- **value_deserializer**: Convierte JSON bytes a objetos Python\n",
        "\n",
        "### Beneficios de esta configuraci√≥n:\n",
        "- Procesamiento confiable con manejo de offsets\n",
        "- Recuperaci√≥n autom√°tica desde interrupciones\n",
        "- Timeout configurado para evitar bloqueos"
      ],
      "metadata": {
        "id": "dUSXgROKzoEk"
      },
      "id": "dUSXgROKzoEk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n del t√≥pico y consumer\n",
        "topic = 'supplement_products'\n",
        "consumer_group = 'supplement_consumer_group'\n",
        "\n",
        "print(f\"Configurando Kafka Consumer...\")\n",
        "print(f\"T√≥pico objetivo: {topic}\")\n",
        "print(f\"Grupo de consumer: {consumer_group}\")\n",
        "\n",
        "try:\n",
        "    consumer = KafkaConsumer(\n",
        "        topic,\n",
        "        bootstrap_servers=['localhost:9092'],\n",
        "        value_deserializer=lambda x: loads(x.decode('utf-8')),\n",
        "        auto_offset_reset='earliest',     # Leer desde el inicio\n",
        "        consumer_timeout_ms=30000,        # Timeout de 30 segundos\n",
        "        group_id=consumer_group,          # Grupo para manejo de offsets\n",
        "        enable_auto_commit=True,          # Auto-commit de offsets\n",
        "        auto_commit_interval_ms=1000,     # Intervalo de commit\n",
        "        max_poll_records=100              # M√°ximo records por poll\n",
        "    )\n",
        "    print(\"‚úÖ Consumer de Kafka configurado exitosamente\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error configurando Kafka Consumer: {e}\")\n",
        "    print(\"Soluci√≥n: Verifica que Kafka est√© ejecut√°ndose en localhost:9092\")\n",
        "    raise e"
      ],
      "metadata": {
        "id": "jbMWp16Rz6-v"
      },
      "id": "jbMWp16Rz6-v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificaci√≥n de T√≥picos y Validaciones\n",
        "\n",
        "### Antes de iniciar el consumo, verificamos que:\n",
        "1. El t√≥pico existe en Kafka\n",
        "2. Hay mensajes disponibles para procesar\n",
        "3. La configuraci√≥n es correcta\n",
        "\n",
        "### Informaci√≥n mostrada:\n",
        "- Lista de t√≥picos disponibles\n",
        "- Estado del t√≥pico objetivo\n",
        "- Particiones y offsets disponibles\n"
      ],
      "metadata": {
        "id": "dVGzRuRx0KQU"
      },
      "id": "dVGzRuRx0KQU"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Verificando configuraci√≥n de Kafka...\")\n",
        "\n",
        "try:\n",
        "    # Obtener lista de t√≥picos disponibles\n",
        "    available_topics = consumer.topics()\n",
        "    print(f\"T√≥picos disponibles: {sorted(list(available_topics))}\")\n",
        "\n",
        "    # Verificar si nuestro t√≥pico existe\n",
        "    if topic in available_topics:\n",
        "        print(f\"‚úÖ T√≥pico '{topic}' encontrado y listo para consumo\")\n",
        "\n",
        "        # Obtener informaci√≥n de particiones\n",
        "        partitions = consumer.partitions_for_topic(topic)\n",
        "        if partitions:\n",
        "            print(f\"Particiones disponibles: {sorted(list(partitions))}\")\n",
        "    else:\n",
        "        print(f\"‚ùå T√≥pico '{topic}' NO encontrado\")\n",
        "        print(\"Soluciones posibles:\")\n",
        "        print(\"   1. Ejecutar primero el producer para crear el t√≥pico\")\n",
        "        print(\"   2. Crear el t√≥pico manualmente:\")\n",
        "        print(f\"      bin/kafka-topics.sh --create --topic {topic} --bootstrap-server localhost:9092\")\n",
        "\n",
        "        # Mostrar t√≥picos similares si existen\n",
        "        similar_topics = [t for t in available_topics if 'supplement' in t.lower()]\n",
        "        if similar_topics:\n",
        "            print(f\"üîç T√≥picos similares encontrados: {similar_topics}\")\n",
        "\n",
        "        exit(1)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error verificando t√≥picos: {e}\")\n",
        "    raise e"
      ],
      "metadata": {
        "id": "WinD0QJn0Zqi"
      },
      "id": "WinD0QJn0Zqi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funciones de Utilidad para Procesamiento\n",
        "\n",
        "### Definimos funciones auxiliares para:\n",
        "- Validar estructura de mensajes\n",
        "- Procesar datos de productos\n",
        "- Generar estad√≠sticas en tiempo real\n",
        "- Manejar errores de datos"
      ],
      "metadata": {
        "id": "Yyemm1h70gxf"
      },
      "id": "Yyemm1h70gxf"
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_message_structure(message_data):\n",
        "    \"\"\"\n",
        "    Valida que el mensaje tenga la estructura esperada\n",
        "\n",
        "    Args:\n",
        "        message_data (dict): Datos del mensaje de Kafka\n",
        "\n",
        "    Returns:\n",
        "        tuple: (is_valid, error_message)\n",
        "    \"\"\"\n",
        "    required_fields = ['search_category', 'timestamp']\n",
        "\n",
        "    for field in required_fields:\n",
        "        if field not in message_data:\n",
        "            return False, f\"Campo requerido '{field}' no encontrado\"\n",
        "\n",
        "    # Validar que tenga datos de producto\n",
        "    if not message_data.get('title'):\n",
        "        return False, \"T√≠tulo del producto no encontrado\"\n",
        "\n",
        "    return True, None\n",
        "\n",
        "def process_product_data(kafka_message, message_data):\n",
        "    \"\"\"\n",
        "    Procesa y estructura los datos del producto para MongoDB\n",
        "\n",
        "    Args:\n",
        "        kafka_message: Mensaje original de Kafka\n",
        "        message_data (dict): Datos deserializados del mensaje\n",
        "\n",
        "    Returns:\n",
        "        dict: Documento estructurado para MongoDB\n",
        "    \"\"\"\n",
        "    # Preparar metadata de Kafka\n",
        "    metadata = {\n",
        "        \"kafka_topic\": kafka_message.topic,\n",
        "        \"kafka_partition\": kafka_message.partition,\n",
        "        \"kafka_offset\": kafka_message.offset,\n",
        "        \"processed_at\": datetime.now().isoformat(),\n",
        "        \"consumer_group\": consumer_group\n",
        "    }\n",
        "\n",
        "    # Estructurar documento para MongoDB\n",
        "    mongo_doc = {\n",
        "        \"metadata\": metadata,\n",
        "        \"search_category\": message_data.get(\"search_category\"),\n",
        "        \"position\": message_data.get(\"position\"),\n",
        "        \"title\": message_data.get(\"title\"),\n",
        "        \"price\": message_data.get(\"price\"),\n",
        "        \"extracted_price\": message_data.get(\"extracted_price\"),\n",
        "        \"source\": message_data.get(\"source\"),\n",
        "        \"rating\": message_data.get(\"rating\"),\n",
        "        \"reviews\": message_data.get(\"reviews\"),\n",
        "        \"link\": message_data.get(\"link\"),\n",
        "        \"image\": message_data.get(\"image\"),\n",
        "        \"brand\": message_data.get(\"brand\", \"N/A\"),\n",
        "        \"delivery\": message_data.get(\"delivery\", \"N/A\"),\n",
        "        \"original_timestamp\": message_data.get(\"timestamp\")\n",
        "    }\n",
        "\n",
        "    return mongo_doc\n",
        "\n",
        "def display_processing_stats(message_count, start_time, category_counter):\n",
        "    \"\"\"\n",
        "    Muestra estad√≠sticas de procesamiento en tiempo real\n",
        "\n",
        "    Args:\n",
        "        message_count (int): N√∫mero total de mensajes procesados\n",
        "        start_time (float): Timestamp de inicio del procesamiento\n",
        "        category_counter (Counter): Contador de productos por categor√≠a\n",
        "    \"\"\"\n",
        "    elapsed_time = time.time() - start_time\n",
        "    rate = message_count / elapsed_time if elapsed_time > 0 else 0\n",
        "\n",
        "    print(f\"\\nEstad√≠sticas en tiempo real:\")\n",
        "    print(f\"   Tiempo transcurrido: {elapsed_time:.1f}s\")\n",
        "    print(f\"   Mensajes procesados: {message_count}\")\n",
        "    print(f\"   Velocidad promedio: {rate:.2f} msg/s\")\n",
        "    print(f\"   Categor√≠as √∫nicas: {len(category_counter)}\")"
      ],
      "metadata": {
        "id": "UQOAY98Y0n5j"
      },
      "id": "UQOAY98Y0n5j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento Principal de Mensajes\n",
        "\n",
        "### Loop principal que:\n",
        "1. Consume mensajes del t√≥pico de Kafka\n",
        "2. Valida la estructura de cada mensaje\n",
        "3. Procesa y transforma los datos\n",
        "4. Almacena en MongoDB con metadata completa\n",
        "5. Muestra progreso en tiempo real\n",
        "\n",
        "### Funcionalidades incluidas:\n",
        "- **Validaci√≥n robusta**: Verificaci√≥n de estructura de mensajes\n",
        "- **Manejo de errores**: Continuidad ante errores individuales\n",
        "- **Estad√≠sticas en vivo**: Progreso y m√©tricas en tiempo real\n",
        "- **Metadata enriquecida**: Informaci√≥n de Kafka y procesamiento\n",
        "- **Interrupci√≥n controlada**: Manejo elegante de Ctrl+C"
      ],
      "metadata": {
        "id": "Tw4mEF7L0wrg"
      },
      "id": "Tw4mEF7L0wrg"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INICIANDO CONSUMO Y PROCESAMIENTO DE MENSAJES\")\n",
        "print(\"=\"*60)\n",
        "print(\"Presiona Ctrl+C para detener el consumo de forma segura\\n\")\n",
        "\n",
        "# Inicializar contadores y estad√≠sticas\n",
        "message_count = 0\n",
        "successful_inserts = 0\n",
        "failed_inserts = 0\n",
        "validation_errors = 0\n",
        "start_time = time.time()\n",
        "category_counter = Counter()\n",
        "error_log = []\n",
        "\n",
        "try:\n",
        "    for kafka_message in consumer:\n",
        "        message_data = kafka_message.value\n",
        "\n",
        "        # Validar estructura del mensaje\n",
        "        is_valid, validation_error = validate_message_structure(message_data)\n",
        "\n",
        "        if not is_valid:\n",
        "            validation_errors += 1\n",
        "            print(f\"‚ö†Ô∏è Mensaje #{message_count + 1} - Error de validaci√≥n: {validation_error}\")\n",
        "            error_log.append(f\"Validaci√≥n - Offset {kafka_message.offset}: {validation_error}\")\n",
        "            continue\n",
        "\n",
        "        # Mostrar informaci√≥n del mensaje recibido\n",
        "        print(f\"\\nüì® Mensaje #{message_count + 1} recibido\")\n",
        "        print(f\"üìä Partici√≥n: {kafka_message.partition} | Offset: {kafka_message.offset}\")\n",
        "\n",
        "        # Extraer informaci√≥n clave del producto\n",
        "        category = message_data.get('search_category', 'N/A')\n",
        "        title = message_data.get('title', 'Sin t√≠tulo')\n",
        "        price = message_data.get('price', 'N/A')\n",
        "        rating = message_data.get('rating', 'N/A')\n",
        "        reviews = message_data.get('reviews', 0)\n",
        "        source = message_data.get('source', 'N/A')\n",
        "\n",
        "        # Mostrar informaci√≥n del producto\n",
        "        print(f\"Categor√≠a: {category}\")\n",
        "        print(f\"Timestamp: {message_data.get('timestamp', 'N/A')}\")\n",
        "        print(f\"Producto: {title[:60]}{'...' if len(title) > 60 else ''}\")\n",
        "        print(f\"Precio: {price}\")\n",
        "        print(f\"Rating: {rating} ({reviews} reviews)\")\n",
        "        print(f\"Fuente: {source}\")\n",
        "\n",
        "        # Actualizar contadores\n",
        "        category_counter[category] += 1\n",
        "\n",
        "        # Procesar y estructurar datos para MongoDB\n",
        "        try:\n",
        "            mongo_doc = process_product_data(kafka_message, message_data)\n",
        "\n",
        "            # Insertar en MongoDB\n",
        "            result = collection.insert_one(mongo_doc)\n",
        "            print(f\"üíæ Almacenado en MongoDB con ID: {result.inserted_id}\")\n",
        "\n",
        "            successful_inserts += 1\n",
        "            message_count += 1\n",
        "\n",
        "            # Mostrar estad√≠sticas cada 10 mensajes\n",
        "            if message_count % 10 == 0:\n",
        "                display_processing_stats(message_count, start_time, category_counter)\n",
        "\n",
        "        except Exception as e:\n",
        "            failed_inserts += 1\n",
        "            error_msg = f\"Error MongoDB - Offset {kafka_message.offset}: {str(e)}\"\n",
        "            print(f\"‚ùå Error al insertar en MongoDB: {e}\")\n",
        "            error_log.append(error_msg)\n",
        "            logger.error(error_msg)\n",
        "\n",
        "        # Pausa opcional para visualizaci√≥n\n",
        "        time.sleep(0.1)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Consumo detenido por el usuario (Ctrl+C)\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error cr√≠tico durante el consumo: {e}\")\n",
        "    logger.error(f\"Error cr√≠tico: {e}\")\n",
        "finally:\n",
        "    print(\"\\nüîÑ Finalizando consumer...\")\n",
        "    consumer.close()"
      ],
      "metadata": {
        "id": "KruqS2Fi05ly"
      },
      "id": "KruqS2Fi05ly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estad√≠sticas Finales y Reportes\n",
        "\n",
        "### Generamos un reporte final del procesamiento:\n",
        "- M√©tricas de rendimiento b√°sicas\n",
        "- Conteo de √©xitos y errores\n",
        "- Estado final de la conexi√≥n"
      ],
      "metadata": {
        "id": "MRvAgLEr1If7"
      },
      "id": "MRvAgLEr1If7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular m√©tricas finales b√°sicas\n",
        "elapsed_time = time.time() - start_time\n",
        "processing_rate = message_count / elapsed_time if elapsed_time > 0 else 0\n",
        "success_rate = (successful_inserts / (successful_inserts + failed_inserts)) * 100 if (successful_inserts + failed_inserts) > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã RESUMEN DE PROCESAMIENTO COMPLETADO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# M√©tricas b√°sicas\n",
        "print(f\"\\nTiempo total de procesamiento: {elapsed_time:.2f} segundos\")\n",
        "print(f\"Mensajes procesados exitosamente: {successful_inserts}\")\n",
        "print(f\"Velocidad promedio: {processing_rate:.2f} mensajes/segundo\")\n",
        "\n",
        "if validation_errors > 0:\n",
        "    print(f\"‚ö†Ô∏è Errores de validaci√≥n: {validation_errors}\")\n",
        "if failed_inserts > 0:\n",
        "    print(f\"‚ùå Errores de inserci√≥n: {failed_inserts}\")\n",
        "\n",
        "print(f\"üéØ Tasa de √©xito: {success_rate:.1f}%\")\n",
        "\n",
        "# Estado final simple\n",
        "print(f\"\\nEstado Final:\")\n",
        "print(f\"   Datos guardados en MongoDB: fitness_supplements.products\")\n",
        "print(f\"   Los datos est√°n listos para el dashboard de Streamlit\")\n",
        "print(f\"   Finalizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Solo mostrar errores si los hay\n",
        "if error_log:\n",
        "    print(f\"\\n‚ö†Ô∏è Se registraron {len(error_log)} errores - revisar logs para detalles\")\n",
        "\n",
        "print(\"\\n‚úÖ Consumer finalizado correctamente\")"
      ],
      "metadata": {
        "id": "PW2S6Knz1IPQ"
      },
      "id": "PW2S6Knz1IPQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jupy",
      "language": "python",
      "name": "jup_lab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}